{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-cdc0c2ebc289>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/stefanini/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/stefanini/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/stefanini/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/stefanini/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/stefanini/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 120\n",
    "display_step = 10\n",
    "batch_size = 512\n",
    "num_input = 784\n",
    "num_classe = 10\n",
    "dropout = 0.20\n",
    "\n",
    "X = tf.placeholder(\"float32\", [None, num_input])\n",
    "Y = tf.placeholder(\"float32\", [None, num_classe])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(x, dropout = 0.2, reuse = False):\n",
    "    \n",
    "    with tf.variable_scope(\"Conv\", reuse = not reuse):\n",
    "        x = tf.reshape(x, [-1, 28, 28, 1])\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(x, filters=32, padding=\"SAME\", \n",
    "                            kernel_size=[5,5], kernel_initializer=tf.truncated_normal_initializer(stddev=0.2),\n",
    "                                activation=tf.nn.relu, name=\"conv_1\")\n",
    "        pool_conv1 = tf.layers.max_pooling2d(conv1, pool_size=[2,2], strides=[2,2], name=\"pool_1\")\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(pool_conv1, filters=64, padding=\"SAME\",\n",
    "                            kernel_size=[5,5], kernel_initializer=tf.truncated_normal_initializer(stddev=0.2),\n",
    "                                activation=tf.nn.relu, name=\"conv_2\")      \n",
    "        pool_conv2 = tf.layers.max_pooling2d(conv2, pool_size=[2,2], strides=[2,2], name=\"pool_2\")\n",
    "\n",
    "        pool2_flat = tf.reshape(pool_conv2, [-1, 7 * 7 * 64])\n",
    "        dense = tf.layers.dense(pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "        dropout = tf.layers.dropout(inputs=dense, rate=dropout)\n",
    "        \n",
    "        logits = tf.layers.dense(dropout, num_classe)       \n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialização do modelo, calculo do loss e accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-06bb75830aa6>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /home/stefanini/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-06bb75830aa6>:9: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-06bb75830aa6>:17: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-06bb75830aa6>:18: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    }
   ],
   "source": [
    "out, logits = cnn_model(X, reuse=True)\n",
    "\n",
    "#Loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "train_op = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Step 1: Minibatch Loss: 2.884248       accuracy: 0.097656\n",
      " Test Step 1: Minibatch Loss: 2.815013       accuracy: 0.087891\n",
      "\n",
      " Train Step 10: Minibatch Loss: 2.496011       accuracy: 0.138672\n",
      " Test Step 10: Minibatch Loss: 2.446350       accuracy: 0.132812\n",
      "\n",
      " Train Step 20: Minibatch Loss: 2.102013       accuracy: 0.224609\n",
      " Test Step 20: Minibatch Loss: 2.049023       accuracy: 0.261719\n",
      "\n",
      " Train Step 30: Minibatch Loss: 1.510066       accuracy: 0.609375\n",
      " Test Step 30: Minibatch Loss: 1.459704       accuracy: 0.625000\n",
      "\n",
      " Train Step 40: Minibatch Loss: 0.900489       accuracy: 0.787109\n",
      " Test Step 40: Minibatch Loss: 0.819279       accuracy: 0.810547\n",
      "\n",
      " Train Step 50: Minibatch Loss: 0.588410       accuracy: 0.832031\n",
      " Test Step 50: Minibatch Loss: 0.576754       accuracy: 0.835938\n",
      "\n",
      " Train Step 60: Minibatch Loss: 0.467116       accuracy: 0.845703\n",
      " Test Step 60: Minibatch Loss: 0.668316       accuracy: 0.806641\n",
      "\n",
      " Train Step 70: Minibatch Loss: 0.451431       accuracy: 0.869141\n",
      " Test Step 70: Minibatch Loss: 0.381693       accuracy: 0.876953\n",
      "\n",
      " Train Step 80: Minibatch Loss: 0.343824       accuracy: 0.900391\n",
      " Test Step 80: Minibatch Loss: 0.419080       accuracy: 0.873047\n",
      "\n",
      " Train Step 90: Minibatch Loss: 0.462163       accuracy: 0.869141\n",
      " Test Step 90: Minibatch Loss: 0.230423       accuracy: 0.921875\n",
      "\n",
      " Train Step 100: Minibatch Loss: 0.161952       accuracy: 0.955078\n",
      " Test Step 100: Minibatch Loss: 0.158706       accuracy: 0.955078\n",
      "\n",
      " Train Step 110: Minibatch Loss: 0.150576       accuracy: 0.953125\n",
      " Test Step 110: Minibatch Loss: 0.190105       accuracy: 0.941406\n",
      "\n",
      " Train Step 120: Minibatch Loss: 0.129960       accuracy: 0.962891\n",
      " Test Step 120: Minibatch Loss: 0.124319       accuracy: 0.958984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1, epochs+1):\n",
    "        # Prepare Data\n",
    "        # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        losses_train = []\n",
    "        \n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        sess.run([train_op, loss, accuracy], feed_dict={X:batch_x, Y:batch_y})\n",
    "        \n",
    "        _, l, acc = sess.run([train_op, loss, accuracy], feed_dict={X: batch_x, Y:batch_y})\n",
    "        \n",
    "        losses_train.append(l)\n",
    "\n",
    "        if i % display_step == 0 or i == 1:\n",
    "            print(' Train Step %i: Minibatch Loss: %f       accuracy: %f' % (i, l, acc))\n",
    "            \n",
    "        batch_x, batch_y = mnist.test.next_batch(batch_size)\n",
    "        losses_test = []  \n",
    "        l, acc = sess.run([loss, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "        \n",
    "        losses_test.append(l)\n",
    "        \n",
    "        if i % display_step == 0 or i == 1:\n",
    "            print(' Test Step %i: Minibatch Loss: %f       accuracy: %f' % (i, l, acc))\n",
    "            print() \n",
    "            \n",
    "        #sample = sess.run(cnn_model(X), feed_dict={X:batch_x, Y:batch_y})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
